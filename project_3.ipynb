{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ad7338a-ace3-4351-bece-3379e28f3698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured data saved to C:/Users/Siva/Downloads/structured_delhi_cars.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from pandas import json_normalize\n",
    "\n",
    "def safe_literal_eval(value):\n",
    "    \"\"\" Safely evaluate strings to Python literals (dicts, lists) if possible. \"\"\"\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            return ast.literal_eval(value) if value else {}\n",
    "        return value\n",
    "    except (ValueError, SyntaxError):\n",
    "        return {}\n",
    "\n",
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    \"\"\" Recursively flatten a nested dictionary. \"\"\"\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        elif isinstance(v, list):\n",
    "            if len(v) > 0 and isinstance(v[0], dict):\n",
    "                for i, sub_dict in enumerate(v):\n",
    "                    items.extend(flatten_dict(sub_dict, f\"{new_key}_{i}\", sep=sep).items())\n",
    "            else:\n",
    "                items.append((new_key, v))\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "def normalize_column(df, column_name):\n",
    "    \"\"\" Normalize a column containing nested dictionaries or lists. \"\"\"\n",
    "    if column_name in df.columns:\n",
    "        try:\n",
    "            # Convert strings to dictionaries/lists if needed\n",
    "            df[column_name] = df[column_name].apply(safe_literal_eval)\n",
    "            \n",
    "            # Flatten nested structures\n",
    "            normalized_data = df[column_name].apply(lambda x: flatten_dict(x) if isinstance(x, dict) else {})\n",
    "            normalized_df = pd.json_normalize(normalized_data)\n",
    "\n",
    "            # Join the normalized DataFrame with the original DataFrame\n",
    "            df = df.drop(columns=[column_name]).join(normalized_df, rsuffix=f'_{column_name}')\n",
    "        except Exception as e:\n",
    "            print(f\"Error normalizing column '{column_name}': {e}\")\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    # Load the DataFrame\n",
    "    df = pd.read_excel(\"C:/Users/Siva/Downloads/delhi_cars.xlsx\")\n",
    "\n",
    "    # Normalize columns with multi-layer nested data\n",
    "    columns_to_normalize = [\n",
    "        'new_car_detail',\n",
    "        'new_car_overview',\n",
    "        'new_car_feature',\n",
    "        'new_car_specs'\n",
    "    ]\n",
    "\n",
    "    for column in columns_to_normalize:\n",
    "        df = normalize_column(df, column)\n",
    "\n",
    "    # Save the structured DataFrame to a new Excel file or CSV\n",
    "    output_path = \"C:/Users/Siva/Downloads/structured_delhi_cars.xlsx\"\n",
    "    df.to_excel(output_path, index=False)\n",
    "\n",
    "    # Alternatively, save to CSV\n",
    "    # df.to_csv(\"C:/Users/Siva/Downloads/structured_chennai_cars.csv\", index=False)\n",
    "\n",
    "    print(f\"Structured data saved to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "299f65d3-5dff-482d-8f9a-ce8da77b35d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data into a DataFrame (replace 'your_data.csv' with your file path)\n",
    "df = pd.read_excel('C:/Users/Siva/Downloads/structured_delhi_cars.xlsx')\n",
    "\n",
    "# Select the columns you want to keep\n",
    "selected_columns = [\n",
    "    'ft', 'bt', 'km', 'transmission', 'ownerNo', \n",
    "    'oem', 'model', 'modelYear', 'centralVariantId', 'variantName', \n",
    "    'price', 'top_0_value', 'top_1_value', 'top_2_value', 'top_3_value', \n",
    "    'top_4_value', 'top_5_value', 'top_6_value', 'top_7_value', 'top_8_value', \n",
    "    'top_9_value', 'top_0_value_new_car_specs', 'top_1_value_new_car_specs', 'top_2_value_new_car_specs', \n",
    "    'data_0_list_0_value_new_car_specs', 'data_0_list_2_value_new_car_specs', 'data_0_list_3_value_new_car_specs', \n",
    "    'data_0_list_6_value_new_car_specs', 'data_1_list_0_value_new_car_specs', 'data_1_list_1_value_new_car_specs', \n",
    "    'data_1_list_2_value_new_car_specs', 'data_1_list_3_value_new_car_specs', 'data_2_list_2_value_new_car_specs' \n",
    "]  # replace with your column names\n",
    "\n",
    "# Create a new DataFrame with only the selected columns\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "# Save the selected columns to a new CSV file\n",
    "df_selected.to_csv('delhi_columns.csv', index=False)\n",
    "\n",
    "print(\"CSV file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1280111f-9016-4ae6-8d56-91e236e27ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows containing null values have been removed and the cleaned data is saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data into a DataFrame\n",
    "df = pd.read_csv('C:/Users/Siva/delhi_columns.csv')\n",
    "\n",
    "# Remove rows with any null values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame to a new Excel file\n",
    "df_cleaned.to_csv('delhi_data.csv', index=False)\n",
    "\n",
    "print(\"Rows containing null values have been removed and the cleaned data is saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "36d52f39-022d-455f-9110-2a5274975675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names have been successfully changed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data into a DataFrame\n",
    "df = pd.read_csv('C:/Users/Siva/delhi_data.csv')\n",
    "\n",
    "# Define a dictionary with old column names as keys and new column names as values\n",
    "new_column_names = {\n",
    "    'ft': 'Fule_type',\n",
    "    'bt': 'Body_type',\n",
    "    'oem': 'Company',\n",
    "    'top_0_value': 'Registration Year',\n",
    "    'top_1_value': 'Insurance',\n",
    "    'top_3_value': 'Seats',\n",
    "    'top_4_value': 'Kms Driven',\n",
    "    'top_5_value': 'RTO',\n",
    "    'top_6_value': 'Ownership',\n",
    "    'top_7_value': 'Engine CC',\n",
    "    'top_8_value': 'Transmission',\n",
    "    'top_9_value': 'Year of Manufacture',\n",
    "    'top_0_value_new_car_specs': 'Max Power',\n",
    "    'data_0_list_0_value_new_car_specs': 'Colur',\n",
    "    'data_0_list_6_value_new_car_specs': 'Number of Cylinder'\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "df.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "# Save the DataFrame with new column names to a new Excel file\n",
    "df.to_csv('delhi_data1.csv', index=False)\n",
    "\n",
    "print(\"Column names have been successfully changed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db7bb4ee-a595-43bb-a7db-d53767fb65a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns have been successfully removed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data into a DataFrame\n",
    "df = pd.read_csv('C:/Users/Siva/delhi_data1.csv')\n",
    "\n",
    "# List of columns to be removed\n",
    "columns_to_remove = [\n",
    "    'top_1_value_new_car_specs',\n",
    "    'top_2_value',\n",
    "    'top_2_value_new_car_specs',\n",
    "    'data_0_list_2_value_new_car_specs',\n",
    "    'data_0_list_3_value_new_car_specs',\n",
    "    'data_1_list_0_value_new_car_specs',\n",
    "    'data_1_list_1_value_new_car_specs',\n",
    "    'data_1_list_2_value_new_car_specs',\n",
    "    'data_1_list_3_value_new_car_specs',\n",
    "    'data_2_list_2_value_new_car_specs'\n",
    "]\n",
    "\n",
    "# Remove the specified columns\n",
    "df_cleaned = df.drop(columns=columns_to_remove)\n",
    "\n",
    "# Save the DataFrame with columns removed to a new Excel file\n",
    "df_cleaned.to_csv('delhi_columns_data1.csv', index=False)\n",
    "\n",
    "print(\"Columns have been successfully removed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c12564-fb61-4ed6-938a-f0c2067048ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv('D:/project 3/delhi_columns_data1.csv')\n",
    "\n",
    "# Function to clean and convert columns\n",
    "def clean_data(df):\n",
    "    # Convert column names to use underscores\n",
    "    df.columns = [col.replace(' ', '_') for col in df.columns]\n",
    "\n",
    "    # Fuel_type\n",
    "    df['Fule_type'] = df['Fule_type'].astype(str)\n",
    "\n",
    "    # Body_type\n",
    "    df['Body_type'] = df['Body_type'].astype(str)\n",
    "\n",
    "    # km\n",
    "    df['km'] = df['km'].str.replace(',', '').astype(int)\n",
    "\n",
    "    # Transmission\n",
    "    df['transmission'] = df['transmission'].astype(str)\n",
    "\n",
    "    # ownerNo\n",
    "    df['ownerNo'] = df['ownerNo'].astype(int)\n",
    "\n",
    "    # Company\n",
    "    df['Company'] = df['Company'].astype(str)\n",
    "\n",
    "    # model\n",
    "    df['model'] = df['model'].astype(str)\n",
    "\n",
    "    # modelYear\n",
    "    df['modelYear'] = pd.to_datetime(df['modelYear'], format='%Y', errors='coerce').dt.year\n",
    "\n",
    "    # centralVariantId\n",
    "    df['centralVariantId'] = df['centralVariantId'].astype(int)\n",
    "\n",
    "    # variantName\n",
    "    df['variantName'] = df['variantName'].astype(str)\n",
    "\n",
    "    # Registration Year\n",
    "    def extract_year(date_str):\n",
    "        if pd.isna(date_str):\n",
    "            return None\n",
    "        date_str = str(date_str).strip()\n",
    "        formats = ['%Y', '%b %Y', '%b-%Y', '%d-%b-%Y', '%b-%d', '%b %d']\n",
    "        for fmt in formats:\n",
    "            try:\n",
    "                parsed_date = pd.to_datetime(date_str, format=fmt, errors='coerce')\n",
    "                if pd.notna(parsed_date):\n",
    "                    return parsed_date.year\n",
    "            except Exception:\n",
    "                continue\n",
    "        return None\n",
    "\n",
    "    df['Registration_Year'] = df['Registration_Year'].apply(extract_year)\n",
    "\n",
    "    # Insurance\n",
    "    df['Insurance'] = df['Insurance'].astype(str)\n",
    "\n",
    "    # Seats\n",
    "    df['Seats'] = df['Seats'].str.replace(' Seats', '').astype(int)\n",
    "\n",
    "    # Kms Driven\n",
    "    df['Kms_Driven'] = df['Kms_Driven'].str.replace(',', '').str.replace(' Kms', '').astype(int)\n",
    "\n",
    "    # RTO\n",
    "    def clean_rto(rto_str):\n",
    "        if pd.isna(rto_str):\n",
    "            return None\n",
    "        rto_str = str(rto_str).strip().upper()  # Convert to uppercase\n",
    "        # Check if the RTO code starts with valid prefixes and contains valid digits\n",
    "        match = re.match(r'^(WB|UP|HR)\\d{2}$', rto_str)\n",
    "        return rto_str if match else None\n",
    "\n",
    "    df['RTO'] = df['RTO'].apply(clean_rto)\n",
    "    df = df[df['RTO'].notna()]  # Keep only rows with valid RTO codes\n",
    "\n",
    "    # Ownership\n",
    "    df['Ownership'] = df['Ownership'].astype(str)\n",
    "\n",
    "    # Transmission (second mention)\n",
    "    df['Transmission'] = df['Transmission'].astype(str)\n",
    "\n",
    "    # Year of Manufacture\n",
    "    df['Year_of_Manufacture'] = pd.to_datetime(df['Year_of_Manufacture'], format='%Y', errors='coerce').dt.year\n",
    "\n",
    "    # Max Power\n",
    "    def clean_max_power(power_str):\n",
    "        if pd.isna(power_str):\n",
    "            return df['Max_Power'].str.replace(' kmpl', '').replace(' km/kg', '').replace(' CC', '').astype(float).mean()\n",
    "        power_str = str(power_str).replace(' kmpl', '').replace(' km/kg', '').replace(' CC', '').strip()\n",
    "        try:\n",
    "            return float(power_str)\n",
    "        except ValueError:\n",
    "            return df['Max_Power'].str.replace(' kmpl', '').replace(' km/kg', '').replace(' CC', '').astype(float).mean()\n",
    "\n",
    "    df['Max_Power'] = df['Max_Power'].apply(clean_max_power)\n",
    "\n",
    "    # Color\n",
    "    df['Colur'] = df['Colur'].astype(str)\n",
    "\n",
    "    # Number of Cylinder\n",
    "    def clean_cylinder(cyl_str):\n",
    "        if pd.isna(cyl_str):\n",
    "            return df['Number_of_Cylinder'].astype(int).mean()\n",
    "        cyl_str = str(cyl_str).strip()\n",
    "        # Replace known non-numeric values with 4\n",
    "        if cyl_str in ['Yes', 'GDi']:\n",
    "            return 4\n",
    "        try:\n",
    "            numeric_part = re.sub(r'[^\\d]', '', cyl_str)\n",
    "            return int(numeric_part) if numeric_part else 4\n",
    "        except ValueError:\n",
    "            return df['Number_of_Cylinder'].astype(int).mean()\n",
    "\n",
    "    df['Number_of_Cylinder'] = df['Number_of_Cylinder'].apply(clean_cylinder)\n",
    "\n",
    "    # Normalize Price\n",
    "    def normalize_price(price):\n",
    "        if pd.isna(price):\n",
    "            return None\n",
    "        price = str(price).strip()\n",
    "        price = re.sub(r'[^\\d\\.Lakh]', '', price)\n",
    "        if 'Lakh' in price:\n",
    "            price = price.replace('Lakh', '').strip()\n",
    "            try:\n",
    "                return float(price) * 100000\n",
    "            except ValueError:\n",
    "                return None\n",
    "        try:\n",
    "            return float(price)\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    df['price'] = df['price'].apply(normalize_price)\n",
    "\n",
    "    # Clean Engine CC\n",
    "    def clean_engine_cc(engine_cc):\n",
    "        if pd.isna(engine_cc):\n",
    "            return None\n",
    "        engine_cc = str(engine_cc).strip()\n",
    "        numeric_part = re.sub(r'[^\\d]', '', engine_cc)\n",
    "        try:\n",
    "            return int(numeric_part)\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    df['Engine_CC'] = df['Engine_CC'].apply(clean_engine_cc)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Clean the DataFrame\n",
    "df_cleaned = clean_data(df)\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_cleaned.to_csv('D:/project 3/delhi_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a356be8-9191-40f2-a709-f1a2c5311fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('D:/project 3/final/delhi_final.csv')\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Handle missing values\n",
    "# Example: fill missing values with appropriate methods\n",
    "df['price'] = df['price'].fillna(df['price'].median())  # Filling missing 'price' with median\n",
    "df = df.fillna('Unknown')  # Fill other missing values with 'Unknown'\n",
    "\n",
    "# Normalize column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Remove accents and special characters from string columns\n",
    "import unicodedata\n",
    "def remove_accents(input_str):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', input_str)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "df = df.applymap(lambda x: remove_accents(x) if isinstance(x, str) else x)\n",
    "\n",
    "# Convert data types if needed\n",
    "df['price'] = df['price'].astype(float)\n",
    "df['km'] = df['km'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318a8f5a-89bd-4c1e-bb22-2397a9fa7a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('D:/project 3/final/delhi_final.csv')\n",
    "\n",
    "# Calculate summary statistics\n",
    "summary_stats = df.describe(include='all')  # Include all columns\n",
    "print(summary_stats)\n",
    "\n",
    "# Calculate additional statistics\n",
    "mean_price = df['price'].mean()\n",
    "median_price = df['price'].median()\n",
    "mode_price = df['price'].mode()[0]\n",
    "std_dev_price = df['price'].std()\n",
    "\n",
    "print(f\"Mean Price: {mean_price}\")\n",
    "print(f\"Median Price: {median_price}\")\n",
    "print(f\"Mode Price: {mode_price}\")\n",
    "print(f\"Standard Deviation of Price: {std_dev_price}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ab7e0-8833-48e4-8bb0-85b59c8256cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Basic Info\n",
    "print(df.info())\n",
    "\n",
    "# Descriptive Statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Distribution of Numerical Features\n",
    "df.hist(figsize=(12, 10), bins=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of Categorical Variables\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(data=df, x='transmission')\n",
    "plt.title('Distribution of Transmission Types')\n",
    "plt.show()\n",
    "\n",
    "# Price vs. Km Driven Scatter Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=df, x='km', y='price', alpha=0.5)\n",
    "plt.title('Price vs. Km Driven')\n",
    "plt.xlabel('Km Driven')\n",
    "plt.ylabel('Price')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot for Price by Body Type\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(data=df, x='body_type', y='price')\n",
    "plt.title('Price Distribution by Body Type')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e153fea4-86b3-476b-a3d0-669d45153428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of CSV file paths and corresponding city names\n",
    "csv_files = ['file1.csv', 'file2.csv', 'file3.csv', 'file4.csv', 'file5.csv', 'file6.csv']\n",
    "cities = ['chennai', 'bangalore', 'delhi', 'kolkata', 'jaipur', 'hyderabad']\n",
    "\n",
    "# List to store individual DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Load each CSV file into a DataFrame and add the 'city' column\n",
    "for file, city in zip(csv_files, cities):\n",
    "    df = pd.read_csv(file)\n",
    "    df['city'] = city  # Add the 'city' column to the DataFrame\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "df_combined = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "df_combined.to_csv('D:/project 3/final/final_file_project_3.csv', index=False)\n",
    "\n",
    "print(\"Data successfully combined and saved to 'combined_data.csv'.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
